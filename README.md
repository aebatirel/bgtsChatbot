# Knowledge Management Chatbot

A document-centric knowledge management chatbot with RAG (Retrieval-Augmented Generation) capabilities. Upload documents, save them to a persistent knowledge base, and chat with your documents using natural language.

## Quick Start

```bash
# 1. Clone and setup
cd chatbot1
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Configure API key
cp .env.example .env
# Edit .env and add your ANTHROPIC_API_KEY

# 3. Start PostgreSQL with pgvector (requires Docker)
docker-compose up -d

# 4. Start the backend
uvicorn backend.main:app --reload

# 5. Start the frontend (new terminal)
cd frontend-react
npm install
npm run dev
```

Open http://localhost:5173 and start chatting!

---

## Features

### Core Features
- **Chat Interface**: Conversational AI powered by Claude Sonnet 4.5
- **Document Upload**: Support for PDF, DOCX, TXT, and MD files
- **Knowledge Base**: Persistent vector storage with PostgreSQL + pgvector
- **RAG Pipeline**: Semantic search + LLM for accurate, sourced answers
- **Document Preview**: See document contents before saving to KB
- **Source Citations**: Responses include clickable references to source documents

### Document Intelligence (LLM-Powered)
- **Auto-Naming**: Documents automatically named based on content analysis
- **Smart Summarization**: AI-generated summaries for each document
- **Metadata Extraction**: Extracts companies, people, dates, and document type
- **Timeline Events**: Automatically extracts meetings, emails, deadlines from documents
- **Timeless Detection**: Identifies static content (profiles, contacts) vs dated content (meetings, reports)
- **Date Uncertainty**: Prompts user for date if document appears time-sensitive but date is unclear

### Time-Aware RAG
- **Temporal Chunking**: Each chunk stores date metadata for time-aware retrieval
- **Recency Boost**: Recent documents prioritized when queries mention time ("latest", "recent", "Q4")
- **Date Range Filtering**: Search within specific date ranges
- **Company Filtering**: Filter search results by mentioned companies

### Multi-Page Application
- **Chat Page** (`/`): Main conversational interface with document upload
- **Documents Page** (`/documents`): Browse, search, filter, download, and delete documents
- **Timeline Page** (`/timeline`): Visual timeline of extracted events with company/date filters
- **Linked References**: Click any source citation to view the full document details

---

## Tech Stack

| Component | Technology | Why |
|-----------|------------|-----|
| **Backend Framework** | [FastAPI](https://fastapi.tiangolo.com/) | Async, high performance, excellent for RAG apps |
| **LLM** | [Claude Sonnet 4.5](https://docs.anthropic.com/) | Best balance of capability/speed/cost |
| **Embeddings** | [Sentence Transformers](https://www.sbert.net/) | Local, free, no API limits |
| **Database + Vectors** | [PostgreSQL + pgvector](https://github.com/pgvector/pgvector) | Unified storage, no AGPL concerns, excellent performance |
| **RAG Framework** | [LangChain](https://docs.langchain.com/) | Flexible, well-documented |
| **ORM** | SQLAlchemy (async) | Type-safe, async PostgreSQL support with asyncpg |
| **Document Parsing** | pypdfium2, python-docx | Fast PDF/DOCX extraction (commercial-friendly) |
| **Frontend** | React + Tailwind CSS | Modern liquid glass design with Motion.js animations |

### Key Decisions

- **Local embeddings over cloud APIs**: Uses `all-MiniLM-L6-v2` via sentence-transformers - free, fast, no rate limits
- **PostgreSQL + pgvector**: Unified database for relational data and vectors (replaces Qdrant + SQLite dual storage)
- **Docker for PostgreSQL**: Easy setup with `docker-compose up -d`
- **No authentication for MVP**: Single user, can add OAuth/JWT later
- **React frontend with liquid glass design**: Modern glassmorphism UI with Tailwind CSS v4 and Motion.js animations
- **All permissive licenses**: No AGPL dependencies (avoided PyMuPDF, chose pypdfium2)

---

## System Architecture

### High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Frontend (HTML/JS)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   Chat Window   â”‚  â”‚  File Upload    â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                     â”‚
            â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FastAPI Backend                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Chat Endpoint  â”‚  â”‚ Upload Endpoint â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚           â”‚                    â”‚                             â”‚
â”‚           â–¼                    â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚         Document Processor               â”‚                â”‚
â”‚  â”‚  - Parse PDF/DOCX/TXT                   â”‚                â”‚
â”‚  â”‚  - Extract text & metadata              â”‚                â”‚
â”‚  â”‚  - Generate preview                     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                    â”‚                                         â”‚
â”‚                    â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚         Knowledge Base Service           â”‚                â”‚
â”‚  â”‚  - Chunk documents                       â”‚                â”‚
â”‚  â”‚  - Generate embeddings (local)           â”‚                â”‚
â”‚  â”‚  - Store in PostgreSQL (pgvector)        â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                    â”‚                                         â”‚
â”‚                    â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚         RAG Query Engine                 â”‚                â”‚
â”‚  â”‚  - Semantic search (pgvector)            â”‚                â”‚
â”‚  â”‚  - Context retrieval                     â”‚                â”‚
â”‚  â”‚  - Claude API for answers               â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   PostgreSQL + pgvector       â”‚
          â”‚  (unified: data + vectors)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Details

| Component | File | Responsibility |
|-----------|------|----------------|
| **FastAPI App** | `backend/main.py` | HTTP server, CORS, routing, lifespan |
| **Config** | `backend/config.py` | Environment variables, settings |
| **Chat Router** | `backend/routers/chat.py` | `/api/chat` endpoint |
| **Documents Router** | `backend/routers/documents.py` | Upload, save, list, download, delete |
| **Timeline Router** | `backend/routers/timeline.py` | Timeline events API with filters |
| **Document Processor** | `backend/services/document_processor.py` | Parse PDF/DOCX/TXT |
| **Document Intelligence** | `backend/services/document_intelligence.py` | LLM metadata extraction (Claude) |
| **Knowledge Base** | `backend/services/knowledge_base.py` | pgvector + local embeddings + time-aware search |
| **Chat Service** | `backend/services/chat_service.py` | RAG orchestration + time-hint detection |
| **LLM Service** | `backend/services/llm_service.py` | Claude API wrapper |
| **Text Processing** | `backend/utils/text_processing.py` | Chunking, cleaning |

---

## Data Flow Diagrams

### Document Upload Flow

```
User selects file
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /api/upload â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DocumentProcessor           â”‚
â”‚   - Validate file type        â”‚
â”‚   - Extract text (PyMuPDF/    â”‚
â”‚     python-docx)              â”‚
â”‚   - Generate preview (500ch)  â”‚
â”‚   - Store in temp memory      â”‚
â”‚   - Return upload_id          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response to Frontend        â”‚
â”‚   {                           â”‚
â”‚     upload_id: "uuid",        â”‚
â”‚     filename: "doc.pdf",      â”‚
â”‚     preview: "First 500ch..", â”‚
â”‚     message: "Save to KB?"    â”‚
â”‚   }                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      User clicks "Save"
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /api/documents/save     â”‚
â”‚  { upload_id: "uuid" }        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DocumentIntelligence (LLM)  â”‚
â”‚   - Auto-generate name        â”‚
â”‚   - Create summary            â”‚
â”‚   - Extract dates/companies   â”‚
â”‚   - Identify timeline events  â”‚
â”‚   - Detect if timeless        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   KnowledgeBaseService        â”‚
â”‚   1. Chunk text with dates    â”‚
â”‚   2. Generate embeddings      â”‚
â”‚      (sentence-transformers)  â”‚
â”‚   3. Bulk insert to PostgreSQLâ”‚
â”‚      (document_chunks table   â”‚
â”‚       with pgvector)          â”‚
â”‚   4. Also saves to PostgreSQL:â”‚
â”‚      - Document record        â”‚
â”‚      - DocumentMetadata       â”‚
â”‚      - TimelineEvents         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Chat/RAG Flow

```
User sends message
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /api/chat   â”‚
â”‚  {                â”‚
â”‚    message: "...",â”‚
â”‚    use_kb: true   â”‚
â”‚  }                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ChatService                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. RETRIEVE                 â”‚
â”‚   KnowledgeBaseService.search â”‚
â”‚   - Embed query (local)       â”‚
â”‚   - pgvector cosine search    â”‚
â”‚   - Return relevant chunks    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   2. AUGMENT                  â”‚
â”‚   Build prompt with context:  â”‚
â”‚   "Use this context:          â”‚
â”‚    [chunk1] [chunk2]..."      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   3. GENERATE                 â”‚
â”‚   LLMService.chat             â”‚
â”‚   - Send to Claude Sonnet 4.5 â”‚
â”‚   - Get response              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response                    â”‚
â”‚   {                           â”‚
â”‚     message: "Answer...",     â”‚
â”‚     sources: [                â”‚
â”‚       {filename, snippet,     â”‚
â”‚        relevance_score}       â”‚
â”‚     ]                         â”‚
â”‚   }                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Database Schema

### PostgreSQL Tables (backend/models/database.py)

All data stored in a single PostgreSQL database with pgvector extension for vector similarity search.

#### Documents Table
```sql
CREATE TABLE documents (
    id              SERIAL PRIMARY KEY,
    filename        VARCHAR(255) NOT NULL,
    original_filename VARCHAR(255) NOT NULL,
    file_type       VARCHAR(50) NOT NULL,
    file_size       INTEGER NOT NULL,
    content_preview TEXT,
    full_text       TEXT,
    stored_file_path VARCHAR(500),  -- Path to original file for download
    chunk_count     INTEGER DEFAULT 0,
    is_indexed      BOOLEAN DEFAULT FALSE,
    created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### Document Metadata Table (LLM-Extracted)
```sql
CREATE TABLE document_metadata (
    id              INTEGER PRIMARY KEY,
    document_id     INTEGER NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    generated_name  VARCHAR(500),      -- LLM-suggested filename
    summary         TEXT,              -- AI-generated summary
    document_type   VARCHAR(50),       -- email_thread, meeting_notes, client_profile, etc.
    is_timeless     BOOLEAN DEFAULT FALSE,  -- Static content vs dated
    primary_date    DATETIME,          -- Main date of the document
    date_range_start DATETIME,         -- For documents spanning a period
    date_range_end  DATETIME,
    date_uncertain  BOOLEAN DEFAULT FALSE,  -- Needs user input
    companies       TEXT,              -- JSON array: ["Acme Corp", "TechStart Inc"]
    people          TEXT,              -- JSON array: ["John Smith", "Jane Doe"]
    created_at      DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

#### Timeline Events Table
```sql
CREATE TABLE timeline_events (
    id              INTEGER PRIMARY KEY,
    document_id     INTEGER NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    event_date      DATETIME NOT NULL,
    event_type      VARCHAR(50),       -- meeting, email, deadline, milestone, action_item
    title           VARCHAR(500) NOT NULL,
    description     TEXT,
    companies       TEXT,              -- JSON array
    people          TEXT,              -- JSON array
    created_at      DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

#### Conversations Table
```sql
CREATE TABLE conversations (
    id          INTEGER PRIMARY KEY,
    title       VARCHAR(255) DEFAULT 'New Conversation',
    created_at  DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at  DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

#### Messages Table
```sql
CREATE TABLE messages (
    id              INTEGER PRIMARY KEY,
    conversation_id INTEGER NOT NULL REFERENCES conversations(id),
    role            VARCHAR(20) NOT NULL,  -- 'user' or 'assistant'
    content         TEXT NOT NULL,
    sources         TEXT,  -- JSON string of source documents
    created_at      DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

#### Document Chunks Table (pgvector)
```sql
-- Requires: CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE document_chunks (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id     INTEGER NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    filename        VARCHAR(255) NOT NULL,  -- For source attribution
    chunk_index     INTEGER NOT NULL,
    text            TEXT NOT NULL,
    embedding       VECTOR(384) NOT NULL,   -- all-MiniLM-L6-v2 dimensions
    chunk_date      TIMESTAMP,              -- For time-aware search
    is_timeless     BOOLEAN DEFAULT FALSE,
    document_type   VARCHAR(50),
    companies       TEXT[],                 -- PostgreSQL array
    people          TEXT[],                 -- PostgreSQL array
    created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX ON document_chunks (document_id);
-- pgvector uses cosine distance for similarity search
```

---

## API Data Models (Pydantic Schemas)

### Request Models

```python
# Chat Request
class ChatRequest:
    message: str                    # User's message
    conversation_id: int | None     # Continue existing conversation
    use_knowledge_base: bool = True # Toggle RAG search

# Document Save Request
class DocumentSaveRequest:
    upload_id: str                  # From upload response
    custom_name: str | None         # Optional rename
```

### Response Models

```python
# Chat Response
class ChatResponse:
    message: str                    # Assistant's response
    conversation_id: int            # For follow-up messages
    sources: list[SourceDocument]   # Cited documents

class SourceDocument:
    document_id: int
    filename: str
    snippet: str                    # Relevant excerpt
    relevance_score: float          # 0.0 - 1.0

# Document Upload Response
class DocumentUploadResponse:
    upload_id: str                  # Use this to save
    filename: str
    file_type: str                  # MIME type
    file_size: int                  # Bytes
    preview: str                    # First 500 chars
    full_text_length: int
    message: str                    # "Save to KB?"

# Document Response
class DocumentResponse:
    id: int
    filename: str
    original_filename: str
    file_type: str
    file_size: int
    content_preview: str | None
    chunk_count: int
    is_indexed: bool
    created_at: datetime
    updated_at: datetime
```

---

## Project Structure

```
chatbot1/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py               # Settings from .env
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic request/response models
â”‚   â”‚   â””â”€â”€ database.py         # SQLAlchemy ORM models (Document, DocumentMetadata, TimelineEvent)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py   # PDF/DOCX/TXT parsing
â”‚   â”‚   â”œâ”€â”€ document_intelligence.py # LLM metadata extraction (Claude)
â”‚   â”‚   â”œâ”€â”€ knowledge_base.py       # pgvector + embeddings + time-aware search
â”‚   â”‚   â”œâ”€â”€ chat_service.py         # RAG orchestration + time-hint detection
â”‚   â”‚   â””â”€â”€ llm_service.py          # Claude API wrapper
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat.py             # POST /api/chat
â”‚   â”‚   â”œâ”€â”€ documents.py        # Document CRUD + download endpoints
â”‚   â”‚   â””â”€â”€ timeline.py         # Timeline events API
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ text_processing.py  # Chunking, text cleaning
â”œâ”€â”€ frontend/                   # Legacy vanilla HTML/CSS/JS (deprecated)
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ documents.html
â”‚   â”œâ”€â”€ timeline.html
â”‚   â”œâ”€â”€ styles.css
â”‚   â”œâ”€â”€ app.js
â”‚   â”œâ”€â”€ documents.js
â”‚   â””â”€â”€ timeline.js
â”œâ”€â”€ frontend-react/             # NEW: React + Tailwind Liquid Glass UI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.tsx            # App entry point
â”‚   â”‚   â”œâ”€â”€ App.tsx             # Router + providers
â”‚   â”‚   â”œâ”€â”€ index.css           # Tailwind + glass utilities
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/             # Glass primitives (GlassCard, GlassButton, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ layout/         # AppShell, Header, GradientBackground
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/           # Chat components
â”‚   â”‚   â”‚   â”œâ”€â”€ documents/      # Document components
â”‚   â”‚   â”‚   â””â”€â”€ timeline/       # Timeline components
â”‚   â”‚   â”œâ”€â”€ pages/              # ChatPage, DocumentsPage, TimelinePage
â”‚   â”‚   â”œâ”€â”€ api/                # API client (axios)
â”‚   â”‚   â”œâ”€â”€ hooks/              # React hooks
â”‚   â”‚   â”œâ”€â”€ types/              # TypeScript types
â”‚   â”‚   â””â”€â”€ lib/                # Utilities (cn, formatters, constants)
â”‚   â”œâ”€â”€ vite.config.ts          # Vite + Tailwind + API proxy
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/                # Stored original files for download
â”œâ”€â”€ docker-compose.yml          # PostgreSQL + pgvector container
â”œâ”€â”€ venv/                       # Python virtual environment
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # API keys (gitignored)
â”œâ”€â”€ .env.example                # Template for .env
â””â”€â”€ README.md                   # This file
```

---

## API Endpoints

### Core Endpoints

| Method | Endpoint | Description | Request Body | Response |
|--------|----------|-------------|--------------|----------|
| `GET` | `/api/health` | Health check | - | `{status, version, services}` |
| `POST` | `/api/chat` | Send message | `ChatRequest` | `ChatResponse` |
| `POST` | `/api/upload` | Upload for preview | `multipart/form-data` | `DocumentUploadResponse` |
| `POST` | `/api/documents/save` | Save to KB with LLM processing | `DocumentSaveRequest` | `DocumentResponse` |
| `GET` | `/api/documents` | List all docs with metadata | - | `DocumentListResponse` |
| `GET` | `/api/documents/{id}` | Get doc details | - | `DocumentResponse` |
| `GET` | `/api/documents/{id}/download` | Download original file | - | File download |
| `DELETE` | `/api/documents/{id}` | Delete from KB | - | `{message}` |

### Timeline Endpoints

| Method | Endpoint | Description | Query Params | Response |
|--------|----------|-------------|--------------|----------|
| `GET` | `/api/timeline` | Get timeline events | `company`, `person`, `start_date`, `end_date`, `event_type`, `limit`, `offset` | `TimelineResponse` |
| `GET` | `/api/timeline/companies` | List all companies | - | `CompaniesListResponse` |
| `GET` | `/api/timeline/event-types` | List all event types | - | `{event_types: string[]}` |

### Frontend Pages

| Route | Page | Description |
|-------|------|-------------|
| `/` | Chat | Main conversational interface with upload |
| `/documents` | Documents | Browse, filter, download, delete documents |
| `/timeline` | Timeline | Visual event timeline with filters |

### Example API Calls

```bash
# Health check
curl http://localhost:8000/api/health

# Chat (without KB)
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello!", "use_knowledge_base": false}'

# Chat (with KB search)
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What do my documents say about X?", "use_knowledge_base": true}'

# Upload document
curl -X POST http://localhost:8000/api/upload \
  -F "file=@document.pdf"

# Save to knowledge base
curl -X POST http://localhost:8000/api/documents/save \
  -H "Content-Type: application/json" \
  -d '{"upload_id": "abc-123-uuid"}'

# List documents
curl http://localhost:8000/api/documents

# Delete document
curl -X DELETE http://localhost:8000/api/documents/1
```

---

## Document Intelligence (LLM Extraction)

When a document is saved, it passes through the Document Intelligence service which uses Claude to extract structured metadata:

### Extraction Process

```
Document Text
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Claude API (Structured Output) â”‚
â”‚  - Analyzes full document text  â”‚
â”‚  - Uses tool_use for JSON       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extracted Metadata             â”‚
â”‚  - suggested_name: string       â”‚
â”‚  - summary: string (2-3 sent)   â”‚
â”‚  - document_type: enum          â”‚
â”‚  - is_timeless: boolean         â”‚
â”‚  - primary_date: ISO date       â”‚
â”‚  - companies: string[]          â”‚
â”‚  - people: string[]             â”‚
â”‚  - events: TimelineEvent[]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Document Types

| Type | Description | Example |
|------|-------------|---------|
| `email_thread` | Email conversations | Client correspondence |
| `meeting_notes` | Meeting summaries | Weekly sync notes |
| `client_profile` | Company/contact info | Account overview |
| `report` | Analysis/reports | Quarterly review |
| `contract` | Legal agreements | Service agreement |
| `proposal` | Business proposals | Project proposal |
| `notes` | General notes | Research notes |
| `other` | Unclassified | Misc documents |

### Timeline Event Types

| Type | Icon | Description |
|------|------|-------------|
| `meeting` | ðŸ¤ | Scheduled meetings, calls |
| `email` | ðŸ“§ | Important email exchanges |
| `deadline` | â° | Due dates, deliverables |
| `milestone` | ðŸŽ¯ | Project milestones, achievements |
| `action_item` | âœ… | Tasks, follow-ups |

---

## RAG Pipeline Details

### Text Chunking Strategy

| Parameter | Value | Reason |
|-----------|-------|--------|
| Chunk Size | 1000 chars | Balance between context and precision |
| Chunk Overlap | 200 chars | Preserve context at boundaries |
| Separators | `\n\n`, `\n`, `. `, ` ` | Prefer semantic breaks |

### Embedding Configuration

| Parameter | Value |
|-----------|-------|
| Model | `all-MiniLM-L6-v2` |
| Dimensions | 384 |
| Provider | Sentence Transformers (local) |

### Retrieval Configuration

| Parameter | Value |
|-----------|-------|
| Top K Results | 5 |
| Distance Metric | Cosine Distance (pgvector) |
| Vector Store | PostgreSQL + pgvector |

### Time-Aware Search

The chat service detects temporal hints in queries and adjusts retrieval:

| Hint Type | Examples | Behavior |
|-----------|----------|----------|
| **Months** | "January", "last March" | Filter to that month |
| **Years** | "2024", "last year" | Filter to that year |
| **Quarters** | "Q4", "Q1 2024" | Filter to quarter range |
| **Recency** | "recent", "latest", "newest" | Apply recency boost scoring |
| **Companies** | "Acme", "TechStart" | Filter by company mentions |

**Recency Boost Formula:**
```
final_score = base_score * (1 + recency_boost)
recency_boost = max(0, 1 - (days_old / 365)) * 0.3
```

Documents from the last year get up to 30% score boost, linearly decreasing with age.

---

## React Frontend (Liquid Glass Design)

The new React frontend features a modern **liquid glass/glassmorphism** design with fluid animations.

### Tech Stack

| Component | Technology |
|-----------|------------|
| **Build Tool** | [Vite](https://vite.dev/) |
| **Framework** | React 18 + TypeScript |
| **Styling** | [Tailwind CSS v4](https://tailwindcss.com/) |
| **Animations** | [Motion.js](https://motion.dev/) |
| **Icons** | [Lucide React](https://lucide.dev/) |
| **Routing** | React Router v7 |
| **Data Fetching** | React Query + Axios |

### Design System

#### Glass Effect Classes
```css
.glass        /* Light glass with backdrop blur */
.glass-heavy  /* Stronger blur for modals */
.glass-card   /* Card with rounded corners */
.glass-modal  /* Full modal styling */
.glass-input  /* Form input styling */
.glass-button /* Interactive button */
```

#### Color Palette
- **Background**: Soft gradient (light blue â†’ purple â†’ pink)
- **Glass surfaces**: Semi-transparent white with blur
- **Primary accent**: Blue-purple (oklch 60% 0.15 250)
- **Text**: Dark blue-gray tones for readability

#### Animation Patterns
- **Spring physics**: Natural, bouncy interactions
- **Staggered lists**: Cards animate in sequence
- **Hover effects**: Subtle scale and shadow changes
- **Page transitions**: Smooth fade and slide

### Component Library

| Component | Description |
|-----------|-------------|
| `GlassCard` | Container with glass effect, optional accent color |
| `GlassButton` | Animated button with variants (primary, secondary, ghost, danger) |
| `GlassModal` | Overlay modal with spring animation |
| `GlassInput` | Form input with focus ring |
| `GlassSelect` | Dropdown with custom styling |
| `GlassBadge` | Colored badge for types |
| `GlassTag` | Small tag for metadata |
| `TypingIndicator` | Animated dots for loading |

### Pages

| Route | Component | Features |
|-------|-----------|----------|
| `/` | `ChatPage` | Message bubbles, KB toggle, file upload modal |
| `/documents` | `DocumentsPage` | Searchable grid, type filters, detail modal |
| `/timeline` | `TimelinePage` | Vertical timeline, company/date filters |

---

## Setup & Installation

### Prerequisites

- Python 3.10+
- Anthropic API key ([console.anthropic.com](https://console.anthropic.com/))

### Installation

```bash
# Clone/navigate to project
cd chatbot1

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure API keys
cp .env.example .env
# Edit .env and add your API keys
```

### Running

#### Option 1: React Frontend (Recommended)

```bash
# Terminal 1: Start backend
source venv/bin/activate
uvicorn backend.main:app --reload
# Backend runs at http://localhost:8000

# Terminal 2: Start React frontend
cd frontend-react
npm install  # First time only
npm run dev
# Frontend runs at http://localhost:5173
```

The React frontend proxies `/api/*` requests to the backend automatically.

#### Option 2: Legacy Vanilla Frontend

```bash
# Start backend (serves vanilla frontend)
source venv/bin/activate
uvicorn backend.main:app --reload

# Open in browser
open http://localhost:8000
```

### Stopping

Press `Ctrl+C` in both terminals, or:
```bash
pkill -f "uvicorn backend.main"
pkill -f "vite"
```

---

## Configuration

All settings in `.env` (loaded via Pydantic Settings):

```env
# API Keys
ANTHROPIC_API_KEY=sk-ant-...      # Required for Claude

# Database (PostgreSQL with pgvector)
DATABASE_URL=postgresql+asyncpg://chatbot:chatbot@localhost:5432/chatbot

# Upload settings
UPLOAD_DIR=./data/uploads
MAX_UPLOAD_SIZE_MB=50

# Model settings
CLAUDE_MODEL=claude-sonnet-4-5-20250929
EMBEDDING_MODEL=all-MiniLM-L6-v2   # Local sentence-transformers model
EMBEDDING_DIMENSIONS=384

# RAG settings
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=5
```

### Docker Compose (PostgreSQL + pgvector)

```yaml
services:
  db:
    image: pgvector/pgvector:pg16
    container_name: chatbot-postgres
    environment:
      POSTGRES_USER: chatbot
      POSTGRES_PASSWORD: chatbot
      POSTGRES_DB: chatbot
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

volumes:
  pgdata:
```

---

## Usage Guide

### 1. Chat with the Assistant
Simply type messages in the chat box. The assistant uses Claude Sonnet 4.5. Use the navigation header to switch between pages.

### 2. Upload Documents
Click the ðŸ“Ž button to upload PDF, DOCX, TXT, or MD files. You'll see a preview before deciding to save.

### 3. Save to Knowledge Base
After uploading, click "Save to Knowledge Base". The document will be:
- **Analyzed by AI**: Auto-named, summarized, and metadata extracted
- **Time-indexed**: Dates and events extracted for time-aware retrieval
- **Chunked & embedded**: Stored in PostgreSQL (pgvector) for semantic search

The modal will show the AI-generated name, summary, document type, and any extracted companies/people.

### 4. Query Your Documents
With KB toggle ON (ðŸ“š), your questions will search the knowledge base. The system:
- Detects time hints ("recent", "latest", "Q4 2024") and prioritizes recent documents
- Extracts company mentions to filter relevant results
- Returns clickable source citations linking to document details

### 5. Browse Documents
Navigate to the **Documents** page to:
- View all uploaded documents with summaries and metadata
- Filter by document type or search by content
- Click a document card to view full details
- Download original files or delete documents

### 6. View Timeline
Navigate to the **Timeline** page to:
- See all extracted events in chronological order
- Filter by company, event type, or date range
- Click event sources to view the original document

### 7. Toggle KB Search
Click the ðŸ“š button to toggle knowledge base search on/off. When OFF, it's a direct chat with Claude.

---

## PRD Requirements Status

Based on the original Product Requirements Document:

### Implemented (MVP + Phase 2)

| Requirement | Status | Notes |
|-------------|--------|-------|
| Natural language query interface | âœ… | Claude Sonnet 4.5 |
| Document upload (PDF, DOCX, TXT) | âœ… | PyMuPDF + python-docx |
| Document preview before saving | âœ… | 500 char preview |
| Knowledge base storage | âœ… | PostgreSQL + pgvector |
| Semantic search with RAG | âœ… | Local embeddings (sentence-transformers) |
| Source citations in responses | âœ… | Clickable links to document details |
| Chat conversation history | âœ… | Session-based |
| Document deletion | âœ… | Removes from PostgreSQL (cascades to chunks) |
| Health check endpoint | âœ… | `/api/health` |
| **LLM document intelligence** | âœ… | Auto-naming, summaries, metadata extraction |
| **Time-aware RAG** | âœ… | Date extraction, recency boost, temporal queries |
| **Timeline visualization** | âœ… | Event extraction, company/date filtering |
| **Documents management page** | âœ… | Browse, search, filter, download, delete |
| **Multi-page navigation** | âœ… | Chat, Documents, Timeline pages |
| **Original file download** | âœ… | Stored files available for download |

### Deferred (Phase 3+)

| Feature | Notes |
|---------|-------|
| User authentication | Can add OAuth/JWT |
| Multi-tenant data isolation | Requires auth first |
| Email integration | Gmail/Outlook API |
| CRM integration (HubSpot) | HubSpot API |
| ATS integration | Varies by provider |
| Real-time streaming responses | SSE implementation |
| Conversation history persistence | Currently session-based |
| XLSX/CSV support | Add pandas |
| Image OCR | Add pytesseract |

---

## Dependencies

```txt
# Core
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
python-multipart>=0.0.6

# LLM & Embeddings
anthropic>=0.40.0
sentence-transformers>=5.0.0

# LangChain
langchain>=0.3.0
langchain-anthropic>=0.3.0
langchain-text-splitters>=0.3.0

# Database (PostgreSQL + pgvector)
sqlalchemy>=2.0.0
asyncpg>=0.29.0
pgvector>=0.2.5
greenlet>=3.0.0

# Document Processing
pypdfium2>=4.0.0
python-docx>=1.1.0

# Utilities
python-dotenv>=1.0.0
pydantic>=2.5.0
pydantic-settings>=2.1.0
aiofiles>=23.2.1
```

---

## Resources & References

### Documentation
- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [LangChain RAG Tutorial](https://docs.langchain.com/oss/python/langchain/rag)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Anthropic Claude API](https://docs.anthropic.com/)
- [Sentence Transformers](https://www.sbert.net/)
- [SQLAlchemy Async](https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html)

### Research & Best Practices
- [RAG Best Practices (TowardsDataScience)](https://towardsdatascience.com/six-lessons-learned-building-rag-systems-in-production/)
- [Vector Database Comparison (DataCamp)](https://www.datacamp.com/blog/the-top-5-vector-databases)
- [Embedding Models Comparison](https://research.aimultiple.com/embedding-models/)
- [pgvector Performance Guide](https://github.com/pgvector/pgvector#performance)

### Templates & Examples
- [FastAPI + LangChain RAG](https://github.com/mazzasaverio/fastapi-langchain-rag)
- [LlamaIndex RAG Application](https://www.kdnuggets.com/building-a-rag-application-using-llamaindex)
- [Anthropic Claude Cookbooks](https://github.com/anthropics/claude-cookbooks)

---

## Future Enhancements

1. **Authentication**: Add OAuth2/JWT for multi-user support
2. **Streaming Responses**: SSE for real-time token streaming
3. **Email Integration**: Connect Gmail/Outlook for auto-ingestion
4. **CRM Integration**: HubSpot API for contact/company data
5. **Reranking**: Add cross-encoder reranking for better retrieval
6. **Document Types**: Add support for XLSX, images (OCR)
7. **Full Dockerization**: Containerize the entire app (backend + frontend)
8. **Hybrid Search**: Combine BM25 keyword search with vector search (PostgreSQL full-text + pgvector)
9. **Query Rewriting**: LLM-based query expansion for better retrieval
10. **Company/Person Profiles**: Auto-generate profiles from extracted mentions
11. **Relationship Graph**: Visualize connections between companies, people, and documents
12. **Calendar Integration**: Sync timeline events with Google/Outlook calendars
13. **HNSW Index**: Add pgvector HNSW index for faster similarity search at scale

---

## License

Private/Internal Use

All dependencies use permissive licenses (MIT, Apache 2.0, BSD, PostgreSQL License). No AGPL dependencies.

---

*Built with Claude Code - January 2025*
*Migrated to PostgreSQL + pgvector - January 2026*
